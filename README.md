# Прогнозирование покупки оборудования клиентом

## Задача
Разработка модели склонности (бинарной классификации) к покупке клиентом оборудования после коммуникации с ним в одном из каналов.

Качество сделанных предсказаний оценивается по метрике ROC AUC между истинными значениями и значениями, полученными в ходе исследования.

## Описание данных

Признаки

  Датасет собран для случайного множества клиентов (id – идентификатор клиента), с которыми была попытка коммуникации в одном из каналов (channel_name).

  Целевая переменная (target) равна единице, если после коммуникации с клиентом была продажа оборудования и нулю если нет.

  Поле period соответствует месяцу сбора признаков на клиента. Лаг между датой коммуникации и сборкой признаков на клиента.

Файлы:

* dataset_train.parquet - тренировочный датасет;
* features_oot.parquet - тестовый датасет;
* features_types.json - описание типов признаков;
* *sample_submission.csv *- пример файла с загружаемыми результатами;
* Для каждой пары 'id' + 'period' собрано более 2500 признаков.

Названия признаков интерпретируются следующим образом:

    <модуль><номер признака><глубина агрегации>_<тип>

Если признак построен как агрегат (например сумма за период), то указывается <глубина агрегации> в месяцах, в противном случае ставится 0. Также, в качестве <глубина агрегации> может быть запись вида '3d6', что указывает на отношение агрегата за 3 месяца к агрегату за 6 месяцев.

Различные типы признаков (<тип>) описаны ниже:

* flg - флаг (значение 1 или 0)
* ctg - категориальный признак
* num - числовой признак
* dt - дата
* cnt -количество
* sum -сумма
* avg - среднее
* sumpct -персентиль по сумме
* part - доля

В файле features_types.json дополнительно записан словарь, где для каждой фичи в соответствие ставится тип из списка (numeric, categorical_int, categorical_string)

## Используемые библиотеки
*pandas, numpy, seaborn, sklearn, lightgbm, catboost*

## Выводы:

При проверке на публичном датасете самая высокая метрика ROC-AUC, которую удалось достичь, 0,661. Ее удалось добиться достаточно подробным подбором признаков на модели LightGBM.

Также была опробована модель Catboost, которая не дала метрику значительно выше, но по времени расчета была гораздо весомее.

На скрытой выборке результат получился 0,66. Это говорит о том, что сама модель устойчива и не потеряла в качестве.

| ML model | ROC-AUC_public | ROC-AUC_private |
| ---------------------- |:-----:| :-----:|
| LightGBMClassifier | 0.661 | 0.636 |
| CatBoostClassifier	   | 0.627 | 0.645 |

Очень сильно влияет на метрику значения параметра 'learning_rate', а также размер 'iterations' равный 1000.

Наиболее удачное количество признаков для расчета это 120-150 признаков.

Также хотелось бы отметить, что из-за большого файла данных, из которого брались значения признаков и сами признаки - попробовать посчитать модель Catboost на GPU на GoogleColab было невозможно, так как время сессии было гораздо меньше, чем скорость загрузки документа на сайт. 

В качестве рекомендаций для улучшения кода:

* Провести все этапы предобработки через pipeline;
* Подумать над новыми способами предобработки (подбор признаков и заполнение пропусков);
* Попробовать решить данную задачу математически или через нейронные сети.



